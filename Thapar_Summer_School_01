{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":81971,"databundleVersionId":8916601,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/harsimransinghdalal/byte-me?scriptVersionId=185381292\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport optuna\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-06-25T10:40:20.494992Z","iopub.execute_input":"2024-06-25T10:40:20.495399Z","iopub.status.idle":"2024-06-25T10:40:20.513205Z","shell.execute_reply.started":"2024-06-25T10:40:20.49536Z","shell.execute_reply":"2024-06-25T10:40:20.511667Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"/kaggle/input/thapar-summer-school-2024/sample_submission.csv\n/kaggle/input/thapar-summer-school-2024/train.csv\n/kaggle/input/thapar-summer-school-2024/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Load datasets\ntrain_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/train.csv')\ntest_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/test.csv')\nsample_submission_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/sample_submission.csv')\n\n# Display the first few rows of each dataframe to understand their structure\nprint(\"Train DataFrame Head:\")\nprint(train_df.head())\n\nprint(\"\\nTest DataFrame Head:\")\nprint(test_df.head())\n\nprint(\"\\nSample Submission DataFrame Head:\")\nprint(sample_submission_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T10:40:24.47149Z","iopub.execute_input":"2024-06-25T10:40:24.471912Z","iopub.status.idle":"2024-06-25T10:40:24.557657Z","shell.execute_reply.started":"2024-06-25T10:40:24.471878Z","shell.execute_reply":"2024-06-25T10:40:24.556439Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Train DataFrame Head:\n   id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders Edema  \\\n0   0     999  D-penicillamine  21532   M       N            N       N     N   \n1   1    2574          Placebo  19237   F       N            N       N     N   \n2   2    3428          Placebo  13727   F       N            Y       Y     Y   \n3   3    2576          Placebo  18460   F       N            N       N     N   \n4   4     788          Placebo  16658   F       N            Y       N     N   \n\n   Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  Tryglicerides  \\\n0        2.3        316.0     3.35   172.0    1601.0  179.80           63.0   \n1        0.9        364.0     3.54    63.0    1440.0  134.85           88.0   \n2        3.3        299.0     3.55   131.0    1029.0  119.35           50.0   \n3        0.6        256.0     3.50    58.0    1653.0   71.30           96.0   \n4        1.1        346.0     3.65    63.0    1181.0  125.55           96.0   \n\n   Platelets  Prothrombin  Stage Status  \n0      394.0          9.7    3.0      D  \n1      361.0         11.0    3.0      C  \n2      199.0         11.7    4.0      D  \n3      269.0         10.7    3.0      C  \n4      298.0         10.6    4.0      C  \n\nTest DataFrame Head:\n     id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders  \\\n0  7905    3839  D-penicillamine  19724   F       N            Y       N   \n1  7906    2468  D-penicillamine  14975   F       N            N       N   \n2  7907      51          Placebo  13149   F       N            Y       N   \n3  7908    2330  D-penicillamine  20510   F       N            N       N   \n4  7909    1615  D-penicillamine  21904   F       N            Y       N   \n\n  Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n0     N        1.2        546.0     3.37    65.0    1636.0  151.90   \n1     N        1.1        660.0     4.22    94.0    1257.0  151.90   \n2     Y        2.0        151.0     2.96    46.0     961.0   69.75   \n3     N        0.6        293.0     3.85    40.0     554.0  125.55   \n4     N        1.4        277.0     2.97   121.0    1110.0  125.00   \n\n   Tryglicerides  Platelets  Prothrombin  Stage  \n0           90.0      430.0         10.6    2.0  \n1          155.0      227.0         10.0    2.0  \n2          101.0      213.0         13.0    4.0  \n3           56.0      270.0         10.6    2.0  \n4          126.0      221.0          9.8    1.0  \n\nSample Submission DataFrame Head:\n     id  Status_C  Status_CL  Status_D\n0  7905  0.628084   0.034788  0.337128\n1  7906  0.628084   0.034788  0.337128\n2  7907  0.628084   0.034788  0.337128\n3  7908  0.628084   0.034788  0.337128\n4  7909  0.628084   0.034788  0.337128\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.decomposition import PCA\nfrom scipy.stats import randint\n\n# Custom transformer for outlier treatment\nclass OutlierTreatment(BaseEstimator, TransformerMixin):\n    def __init__(self, factor=1.5):\n        self.factor = factor\n\n    def fit(self, X, y=None):\n        X_df = pd.DataFrame(X)\n        self.Q1 = X_df.quantile(0.25)\n        self.Q3 = X_df.quantile(0.75)\n        self.IQR = self.Q3 - self.Q1\n        return self\n\n    def transform(self, X):\n        X_out = pd.DataFrame(X).copy()\n        lower_bound = self.Q1 - self.factor * self.IQR\n        upper_bound = self.Q3 + self.factor * self.IQR\n        X_out = np.clip(X_out, lower_bound, upper_bound, axis=1)\n        return X_out\n\n# Custom transformer for removing highly correlated features\nclass CorrelationFilter(BaseEstimator, TransformerMixin):\n    def __init__(self, threshold=0.9):\n        self.threshold = threshold\n\n    def fit(self, X, y=None):\n        X_df = pd.DataFrame(X)\n        corr_matrix = X_df.corr().abs()\n        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n        self.to_drop = [column for column in upper.columns if any(upper[column] > self.threshold)]\n        return self\n\n    def transform(self, X):\n        X_df = pd.DataFrame(X)\n        return X_df.drop(columns=self.to_drop, errors='ignore')\n\n# Load datasets\ntrain_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/train.csv')\ntest_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/test.csv')\nsample_submission_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/sample_submission.csv')\n\n# Identify features and target\nfeatures = train_df.drop(columns=['id', 'Status'])\ntarget = train_df['Status']\n\n# Split categorical and numerical features\nnumerical_features = features.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features = features.select_dtypes(include=['object']).columns\n\n# Preprocessing for numerical data\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('outlier', OutlierTreatment(factor=1.5)),\n    ('corr_filter', CorrelationFilter(threshold=0.9)),\n    ('scaler', StandardScaler()),\n    ('pca', PCA(n_components=0.95))  # Keep 95% of variance\n])\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])\n\n# Create the preprocessing and training pipeline\nmodel = Pipeline(steps=[('preprocessor', preprocessor),\n                        ('classifier', RandomForestClassifier(random_state=42))])\n\n# Split the data into training and validation sets\nX_train, X_valid, y_train, y_valid = train_test_split(features, target, test_size=0.2, random_state=42)\n\n# Define the hyperparameters to tune\nparam_dist = {\n    'classifier__n_estimators': randint(100, 1000),\n    'classifier__max_depth': [10, 20, 30, 40, 50, None],\n    'classifier__min_samples_split': randint(2, 20),\n    'classifier__min_samples_leaf': randint(1, 20),\n    'preprocessor__num__outlier__factor': [1.0, 1.5, 2.0]\n}\n\n# Perform randomized search\nn_iter_search = 10  # Reduced number of iterations\nrandom_search = RandomizedSearchCV(model, param_distributions=param_dist,\n                                   n_iter=n_iter_search, cv=5, scoring='neg_log_loss', n_jobs=-1)\n\nrandom_search.fit(X_train, y_train)\n\n# Get the best hyperparameters\nbest_params = random_search.best_params_\nprint(f\"Best Hyperparameters: {best_params}\")\n\n# Fit the model with the best hyperparameters\nbest_model = random_search.best_estimator_\nbest_model.fit(X_train, y_train)\n\n# Validate the model\ny_valid_pred = best_model.predict_proba(X_valid)\n\n# Calculate log loss on the validation set\nlogloss = log_loss(pd.get_dummies(y_valid), y_valid_pred)\nprint(f\"Validation Log Loss with Best Model: {logloss}\")\n\n# Predict on the test data\ntest_pred = best_model.predict_proba(test_df.drop(columns=['id']))\n\n# Prepare the submission DataFrame\nsubmission_df = pd.DataFrame({\n    'id': test_df['id'],\n    'Status_C': [proba[0] for proba in test_pred],\n    'Status_CL': [proba[1] for proba in test_pred],\n    'Status_D': [proba[2] for proba in test_pred]\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T10:43:54.037929Z","iopub.execute_input":"2024-06-25T10:43:54.038381Z","iopub.status.idle":"2024-06-25T10:46:52.760287Z","shell.execute_reply.started":"2024-06-25T10:43:54.038344Z","shell.execute_reply":"2024-06-25T10:46:52.759008Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Best Hyperparameters: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 3, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 867, 'preprocessor__num__outlier__factor': 2.0}\nValidation Log Loss with Best Model: 0.5029231551912814\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"     id  Status_C  Status_CL  Status_D\n0  7905  0.608055   0.056674  0.335271\n1  7906  0.782474   0.059518  0.158008\n2  7907  0.204972   0.046288  0.748740\n3  7908  0.933345   0.003649  0.063006\n4  7909  0.667346   0.035209  0.297444","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Status_C</th>\n      <th>Status_CL</th>\n      <th>Status_D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7905</td>\n      <td>0.608055</td>\n      <td>0.056674</td>\n      <td>0.335271</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7906</td>\n      <td>0.782474</td>\n      <td>0.059518</td>\n      <td>0.158008</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7907</td>\n      <td>0.204972</td>\n      <td>0.046288</td>\n      <td>0.748740</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7908</td>\n      <td>0.933345</td>\n      <td>0.003649</td>\n      <td>0.063006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7909</td>\n      <td>0.667346</td>\n      <td>0.035209</td>\n      <td>0.297444</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}