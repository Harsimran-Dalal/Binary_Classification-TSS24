{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea03f4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T10:28:33.677490Z",
     "iopub.status.busy": "2024-06-25T10:28:33.676951Z",
     "iopub.status.idle": "2024-06-25T10:28:37.377225Z",
     "shell.execute_reply": "2024-06-25T10:28:37.375317Z"
    },
    "papermill": {
     "duration": 3.708586,
     "end_time": "2024-06-25T10:28:37.380522",
     "exception": false,
     "start_time": "2024-06-25T10:28:33.671936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/thapar-summer-school-2024/sample_submission.csv\n",
      "/kaggle/input/thapar-summer-school-2024/train.csv\n",
      "/kaggle/input/thapar-summer-school-2024/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0405a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T10:28:37.389091Z",
     "iopub.status.busy": "2024-06-25T10:28:37.388479Z",
     "iopub.status.idle": "2024-06-25T10:28:37.524654Z",
     "shell.execute_reply": "2024-06-25T10:28:37.523036Z"
    },
    "papermill": {
     "duration": 0.144371,
     "end_time": "2024-06-25T10:28:37.528384",
     "exception": false,
     "start_time": "2024-06-25T10:28:37.384013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame Head:\n",
      "   id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders Edema  \\\n",
      "0   0     999  D-penicillamine  21532   M       N            N       N     N   \n",
      "1   1    2574          Placebo  19237   F       N            N       N     N   \n",
      "2   2    3428          Placebo  13727   F       N            Y       Y     Y   \n",
      "3   3    2576          Placebo  18460   F       N            N       N     N   \n",
      "4   4     788          Placebo  16658   F       N            Y       N     N   \n",
      "\n",
      "   Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  Tryglicerides  \\\n",
      "0        2.3        316.0     3.35   172.0    1601.0  179.80           63.0   \n",
      "1        0.9        364.0     3.54    63.0    1440.0  134.85           88.0   \n",
      "2        3.3        299.0     3.55   131.0    1029.0  119.35           50.0   \n",
      "3        0.6        256.0     3.50    58.0    1653.0   71.30           96.0   \n",
      "4        1.1        346.0     3.65    63.0    1181.0  125.55           96.0   \n",
      "\n",
      "   Platelets  Prothrombin  Stage Status  \n",
      "0      394.0          9.7    3.0      D  \n",
      "1      361.0         11.0    3.0      C  \n",
      "2      199.0         11.7    4.0      D  \n",
      "3      269.0         10.7    3.0      C  \n",
      "4      298.0         10.6    4.0      C  \n",
      "\n",
      "Test DataFrame Head:\n",
      "     id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders  \\\n",
      "0  7905    3839  D-penicillamine  19724   F       N            Y       N   \n",
      "1  7906    2468  D-penicillamine  14975   F       N            N       N   \n",
      "2  7907      51          Placebo  13149   F       N            Y       N   \n",
      "3  7908    2330  D-penicillamine  20510   F       N            N       N   \n",
      "4  7909    1615  D-penicillamine  21904   F       N            Y       N   \n",
      "\n",
      "  Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
      "0     N        1.2        546.0     3.37    65.0    1636.0  151.90   \n",
      "1     N        1.1        660.0     4.22    94.0    1257.0  151.90   \n",
      "2     Y        2.0        151.0     2.96    46.0     961.0   69.75   \n",
      "3     N        0.6        293.0     3.85    40.0     554.0  125.55   \n",
      "4     N        1.4        277.0     2.97   121.0    1110.0  125.00   \n",
      "\n",
      "   Tryglicerides  Platelets  Prothrombin  Stage  \n",
      "0           90.0      430.0         10.6    2.0  \n",
      "1          155.0      227.0         10.0    2.0  \n",
      "2          101.0      213.0         13.0    4.0  \n",
      "3           56.0      270.0         10.6    2.0  \n",
      "4          126.0      221.0          9.8    1.0  \n",
      "\n",
      "Sample Submission DataFrame Head:\n",
      "     id  Status_C  Status_CL  Status_D\n",
      "0  7905  0.628084   0.034788  0.337128\n",
      "1  7906  0.628084   0.034788  0.337128\n",
      "2  7907  0.628084   0.034788  0.337128\n",
      "3  7908  0.628084   0.034788  0.337128\n",
      "4  7909  0.628084   0.034788  0.337128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/test.csv')\n",
    "sample_submission_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/sample_submission.csv')\n",
    "\n",
    "# Display the first few rows of each dataframe to understand their structure\n",
    "print(\"Train DataFrame Head:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest DataFrame Head:\")\n",
    "print(test_df.head())\n",
    "\n",
    "print(\"\\nSample Submission DataFrame Head:\")\n",
    "print(sample_submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e857e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-25T10:28:37.536327Z",
     "iopub.status.busy": "2024-06-25T10:28:37.535930Z",
     "iopub.status.idle": "2024-06-25T10:30:44.452024Z",
     "shell.execute_reply": "2024-06-25T10:30:44.450322Z"
    },
    "papermill": {
     "duration": 126.923796,
     "end_time": "2024-06-25T10:30:44.455316",
     "exception": false,
     "start_time": "2024-06-25T10:28:37.531520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 7, 'classifier__n_estimators': 550, 'preprocessor__num__outlier__factor': 1.5}\n",
      "Validation Log Loss with Best Model: 0.4648112006382242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Status_C</th>\n",
       "      <th>Status_CL</th>\n",
       "      <th>Status_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7905</td>\n",
       "      <td>0.645309</td>\n",
       "      <td>0.046594</td>\n",
       "      <td>0.308097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7906</td>\n",
       "      <td>0.777690</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.134591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7907</td>\n",
       "      <td>0.140270</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.804730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7908</td>\n",
       "      <td>0.943173</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.048587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7909</td>\n",
       "      <td>0.640822</td>\n",
       "      <td>0.089053</td>\n",
       "      <td>0.270125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Status_C  Status_CL  Status_D\n",
       "0  7905  0.645309   0.046594  0.308097\n",
       "1  7906  0.777690   0.087719  0.134591\n",
       "2  7907  0.140270   0.055000  0.804730\n",
       "3  7908  0.943173   0.008240  0.048587\n",
       "4  7909  0.640822   0.089053  0.270125"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Custom transformer for outlier treatment\n",
    "class OutlierTreatment(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1.5):\n",
    "        self.factor = factor\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.Q1 = X.quantile(0.25)\n",
    "            self.Q3 = X.quantile(0.75)\n",
    "        else:  # Assuming it's a numpy array\n",
    "            self.Q1 = np.quantile(X, 0.25, axis=0)\n",
    "            self.Q3 = np.quantile(X, 0.75, axis=0)\n",
    "        self.IQR = self.Q3 - self.Q1\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_out = X.copy()\n",
    "        lower_bound = self.Q1 - self.factor * self.IQR\n",
    "        upper_bound = self.Q3 + self.factor * self.IQR\n",
    "        X_out = np.clip(X_out, lower_bound, upper_bound)\n",
    "        return X_out\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/test.csv')\n",
    "sample_submission_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024/sample_submission.csv')\n",
    "\n",
    "# Identify features and target\n",
    "features = train_df.drop(columns=['id', 'Status'])\n",
    "target = train_df['Status']\n",
    "\n",
    "# Split categorical and numerical features\n",
    "numerical_features = features.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = features.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('outlier', OutlierTreatment(factor=1.5)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the preprocessing and training pipeline\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': randint(100, 1000),\n",
    "    'classifier__max_depth': [10, 20, 30, 40, 50, None],\n",
    "    'classifier__min_samples_split': randint(2, 20),\n",
    "    'classifier__min_samples_leaf': randint(1, 20),\n",
    "    'preprocessor__num__outlier__factor': [1.0, 1.5, 2.0]\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "n_iter_search = 10  # Reduced number of iterations\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, scoring='neg_log_loss', n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Fit the model with the best hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_valid_pred = best_model.predict_proba(X_valid)\n",
    "\n",
    "# Calculate log loss on the validation set\n",
    "logloss = log_loss(pd.get_dummies(y_valid), y_valid_pred)\n",
    "print(f\"Validation Log Loss with Best Model: {logloss}\")\n",
    "\n",
    "# Predict on the test data\n",
    "test_pred = best_model.predict_proba(test_df.drop(columns=['id']))\n",
    "\n",
    "# Prepare the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Status_C': [proba[0] for proba in test_pred],\n",
    "    'Status_CL': [proba[1] for proba in test_pred],\n",
    "    'Status_D': [proba[2] for proba in test_pred]\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8916601,
     "sourceId": 81971,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 137.02947,
   "end_time": "2024-06-25T10:30:47.082603",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-25T10:28:30.053133",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
